library(psych)
library(tidyverse)
library(janitor)
library(data.table)
library(openxlsx)
library(stringr)
library(readr)
library(glue)

# Checks variable names between two datasets and displays differences in variable names
############
compare_variable_names <- function(df1, df2) {
  name1 <- deparse(substitute(df1))
  name2 <- deparse(substitute(df2))

  cols1 <- names(df1)
  cols2 <- names(df2)

  identical_cols <- identical(cols1, cols2)
  diff_1_to_2 <- setdiff(cols1, cols2)
  diff_2_to_1 <- setdiff(cols2, cols1)

  # Create and print the summary tibble
  summary_df <- tibble(
    Comparison = paste(name1, "vs", name2),
    Identical = identical_cols
  )

  # Print differences as separate messages
  if (length(diff_1_to_2) > 0) {
    cat("\nIn", name1, "but not in", name2, ":\n", paste(diff_1_to_2, collapse = ", "), "\n")
  } else {
    cat("\nNo variables found in", name1, "that are missing from", name2, "\n")
  }

  if (length(diff_2_to_1) > 0) {
    cat("\nIn", name2, "but not in", name1, ":\n", paste(diff_2_to_1, collapse = ", "), "\n")
  } else {
    cat("\nNo variables found in", name2, "that are missing from", name1, "\n")
  }
}

# compare_variable_names(df1 = grad23, df2 = grad24)

files_by_keywords <- function(
    folder,
    keywords,
    recursive = TRUE,
    ignore_case = TRUE,
    full_names = TRUE
) {
  # Check folder exists
  if (!dir.exists(folder)) {
    stop("❌ The specified folder does not exist: ", folder)
  }

  if (length(keywords) == 0) {
    stop("❌ Please supply at least one keyword to search for.")
  }

  # List files
  files <- list.files(path = folder, recursive = recursive, full.names = full_names)

  # Filter based on keyword pattern
  pattern <- paste0(keywords, collapse = "|")
  matched_files <- files[grepl(pattern, basename(files), ignore.case = ignore_case)]

  if (length(matched_files) == 0) {
    message("🔍 No files matched the keywords: ", paste(keywords, collapse = ", "))
    return(character(0))
  }

  # Show menu for selection
  cat("📂 Matched files:\n")
  choices <- basename(matched_files)
  for (i in seq_along(choices)) {
    cat(sprintf("[%2d] %s\n", i, choices[i]))
  }

  cat("\nEnter numbers of files to select (comma-separated), or press Enter to cancel: ")
  input <- readline()

  if (input == "") {
    message("🚫 Selection cancelled.")
    return(character(0))
  }

  selected_indices <- suppressWarnings(as.integer(strsplit(input, ",")[[1]]))
  selected_indices <- selected_indices[!is.na(selected_indices) & selected_indices >= 1 & selected_indices <= length(matched_files)]

  if (length(selected_indices) == 0) {
    message("⚠️ No valid selections made.")
    return(character(0))
  }

  selected_files <- matched_files[selected_indices]
  return(selected_files)
}

#example usage
# chronic_fact <- files_by_keywords(
#   folder = "T:/Data Warehouse/CDE/Absenteeism",
#   keywords = "fact"
# )

####
load_and_compare_files <- function(
    folder,
    keywords,
    join_method = c("bind_rows", "left_join", "full_join"),
    by = NULL,
    recursive = TRUE,
    ignore_case = TRUE,
    full_names = TRUE,
    require_approval_on_diff = TRUE,
    force = FALSE,
    encoding = NULL,
    id_col = "source_file",
    show_compare_details = TRUE,
    also_run_compare_function = FALSE) {

  library(dplyr); library(stringr)

  `%||%` <- function(x, y) if (is.null(x) || (length(x) == 1 && is.na(x))) y else x

  join_method <- match.arg(join_method)

  # NEW: idempotent code normalizer
  standardize_codes <- function(df) {
    to_chr <- function(x) as.character(x)

    if ("county_code"   %in% names(df)) df$county_code   <- str_pad(gsub("\\D","", to_chr(df$county_code)),   2, pad = "0")
    if ("district_code" %in% names(df)) df$district_code <- str_pad(gsub("\\D","", to_chr(df$district_code)), 5, pad = "0")
    if ("school_code"   %in% names(df)) df$school_code   <- str_pad(gsub("\\D","", to_chr(df$school_code)),   7, pad = "0")

    if ("cds" %in% names(df)) {
      cds <- gsub("\\D","", to_chr(df$cds))
      good <- nchar(cds) == 14
      if (all(c("county_code","district_code","school_code") %in% names(df))) {
        cds[!good] <- paste0(df$county_code, df$district_code, df$school_code)[!good]
      }
      df$cds <- str_pad(cds, 14, pad = "0")
    } else if (all(c("county_code","district_code","school_code") %in% names(df))) {
      df$cds <- paste0(df$county_code, df$district_code, df$school_code)
    }

    df
  }

  selected_files <- files_by_keywords(
    folder = folder,
    keywords = keywords,
    recursive = recursive,
    ignore_case = ignore_case,
    full_names = full_names
  )
  if (length(selected_files) == 0) {
    message("🔍 No files matched the keywords: ", paste(keywords, collapse = ", "))
    return(invisible(NULL))
  }
  if (join_method == "left_join" && length(selected_files) < 2) {
    stop("❌ Need at least two files for left_join.")
  }
  if (join_method == "full_join" && length(selected_files) < 2) {
    stop("❌ Need at least two files for full_join.")
  }

  # ---- read all dfs (force key code columns to character) ----
  dfs <- lapply(
    selected_files,
    function(p) {

      loc <- readr::locale(encoding = encoding %||% "UTF-8")
      force_char_cols <- c("cds","county_code","district_code","school_code")

      # Peek header to know which forced columns are present (case-insensitive)
      hdr <- readr::read_csv(p, n_max = 0, show_col_types = FALSE, locale = loc)

      hdr_names <- names(hdr)

      hdr_names_clean <- trimws(hdr_names)

      present_idx <- which(tolower(hdr_names_clean) %in% force_char_cols)

      present_names <- hdr_names[present_idx]

      if (length(present_names)) {
        # Build a col_types spec: guess everything, override these to character
        spec <- readr::cols(.default = readr::col_guess())
        for (nm in present_names) spec$cols[[nm]] <- readr::col_character()
        df <- readr::read_csv(p, show_col_types = FALSE, locale = loc, col_types = spec)
      } else {
        df <- readr::read_csv(p, show_col_types = FALSE, locale = loc)
      }

      # Normalize all character data to UTF-8 (as you were doing)
      if (ncol(df)) {
        df <- dplyr::mutate(df, dplyr::across(where(is.character), ~ iconv(.x, from = "", to = "UTF-8")))
      }

      # NEW: force/pad codes & rebuild cds when possible
      # functionally like pad_cds_codes

      df <- standardize_codes(df)

      df
    }
  )

  names(dfs) <- basename(selected_files)

  ref_name <- names(dfs)[1]
  ref_df   <- dfs[[1]]
  has_discrepancies <- FALSE

  if (length(dfs) >= 2) {
    for (i in 2:length(dfs)) {
      compare_name <- names(dfs)[i]
      compare_df   <- dfs[[i]]

      cols_ref <- names(ref_df)
      cols_cmp <- names(compare_df)

      only_in_ref <- setdiff(cols_ref, cols_cmp)
      only_in_cmp <- setdiff(cols_cmp, cols_ref)

      same_names <- setequal(cols_ref, cols_cmp)
      same_order <- identical(cols_ref, cols_cmp)

      if (show_compare_details) {
        cat("\n=============================================================\n")
        cat("📋 Comparing ", ref_name, "  vs  ", compare_name, "\n", sep = "")
        cat("-------------------------------------------------------------\n")

        if (length(only_in_ref)) {
          cat("In ", ref_name, " but not in ", compare_name, ":\n  - ",
              paste(only_in_ref, collapse = "\n  - "), "\n", sep = "")
        } else {
          cat("No variables in ", ref_name, " that are missing from ", compare_name, "\n", sep = "")
        }

        if (length(only_in_cmp)) {
          cat("\nIn ", compare_name, " but not in ", ref_name, ":\n  - ",
              paste(only_in_cmp, collapse = "\n  - "), "\n", sep = "")
        } else {
          cat("\nNo variables in ", compare_name, " that are missing from ", ref_name, "\n", sep = "")
        }

        if (same_names && !same_order) {
          cat("\n⚠️ Column names are identical but appear in a different order.\n")
        }

        cat("=============================================================\n")
      }

      if (!same_names) {
        has_discrepancies <- TRUE
      } else if (!same_order) {
        has_discrepancies <- TRUE
        message("⚠️ Column names are the same, but order differs between ", ref_name, " and ", compare_name)
      }

      if (also_run_compare_function && exists("compare_variable_names", mode = "function")) {
        tmp <- new.env(parent = .GlobalEnv)
        ref_sym <- as.name(make.names(ref_name))
        cmp_sym <- as.name(make.names(compare_name))
        assign(as.character(ref_sym), ref_df,     envir = tmp)
        assign(as.character(cmp_sym), compare_df, envir = tmp)
        eval(call("compare_variable_names", ref_sym, cmp_sym), envir = tmp)
      }
    }
  }

  if (has_discrepancies && require_approval_on_diff && !force) {
    if (!interactive()) {
      message("\n⚠️ Differences detected. Aborting join in non-interactive session.")
      return(invisible(NULL))
    }
    resp <- readline("❗ Differences detected (name or order). Proceed with join anyway? (yes/no): ")
    if (tolower(trimws(resp)) != "yes") {
      message("\n⚠️ Please resolve column differences before joining.")
      return(invisible(NULL))
    }
  }

  if (join_method == "bind_rows") {
    if (is.null(id_col)) {
      return(dplyr::bind_rows(dfs))
    } else {
      return(dplyr::bind_rows(dfs, .id = id_col))
    }
  } else {
    if (is.null(by)) stop("❌ For left_join, you must supply `by` with join key(s).")
    out <- dfs[[1]]
    for (i in 2:length(dfs)) {
      out <- switch(
        join_method,
        left_join = dplyr::left_join(out, dfs[[i]], by = by),
        full_join = dplyr::full_join(out, dfs[[i]], by = by),
        stop("❌ Unsupported join_method: ", join_method)
      )
    }

    return(out)
  }
}


#example usage
# chronic_fact_joined <- load_and_compare_files(
#   folder = "T:/Data Warehouse/CDE/Absenteeism",
#   keywords = c("fact"),
#   join_method = "bind_rows",
#   encoding = "latin1
# )

safe_fwrite_warehouse <- function(data, path = NULL,
                        char_cols = c("cds", "county_code", "district_code", "school_code"),
                        compress = FALSE,
                        n_check = 6,
                        log_metadata = NULL,
                        data_year = NULL,
                        data_source = NULL,
                        data_description = NA,
                        user_note = NA,
                        table_name = NULL,
                        dim_description = NULL,
                        log_path = "export_log.csv",
                        canonical_table_id = NULL,
                        dimension_type = NULL) {

  # Construct default path if not provided
  if (is.null(path)) {
    required <- c("data_year", "data_source", "table_name")
    missing_args <- required[!sapply(list(data_year, data_source, table_name), function(x) !is.null(x))]

    if (length(missing_args) > 0) {
      stop(paste0("❌ To auto-generate the path, you must supply: ",
                  paste(missing_args, collapse = ", "), "."))
    }
  }

  # Allow shorthand metadata if log_metadata not provided
  if (is.null(log_metadata)) {
    if (is.null(data_year) || is.null(data_source)) {
      stop("❌ You must supply either `log_metadata` or both `data_year` and `data_source`.")
    }
    log_metadata <- list(
      data_year = data_year,
      data_source = data_source,
      data_description = data_description,
      user_note = user_note
    )
  }

  # Validate that data_description is provided
  if (is.null(log_metadata$data_description) || is.na(log_metadata$data_description) || log_metadata$data_description == "") {
    stop("❌ Please provide a brief description of what's in this data file using `data_description`.")
  }

  # Validate required metadata fields
  required_fields <- c("data_year", "data_source")
  missing_fields <- setdiff(required_fields, names(log_metadata))
  if (length(missing_fields) > 0) {
    stop("❌ Missing required `log_metadata` fields: ",
         paste(missing_fields, collapse = ", "))
  }

  # Validate and standardize data_source values
  allowed_sources <- c("Assessment", "CDE", "Dashboard")
  input_source <- tolower(log_metadata$data_source)
  matched_idx <- match(input_source, tolower(allowed_sources))

  if (is.na(matched_idx)) {
    stop("❌ `data_source` must be one of: ", paste(allowed_sources, collapse = ", "))
  }

  # Store canonical label for logging (title-case)
  log_metadata$data_source <- allowed_sources[matched_idx]

  # Store lowercase version separately if you need it for folder names
  folder_data_source <- tolower(allowed_sources[matched_idx])

  # Validate user_note contains "fact" or "dim"
  if (!grepl("\\bfact\\b|\\bdim\\b", log_metadata$user_note, ignore.case = TRUE)) {
    stop("❌ Your `user_note` must clearly include either 'fact' or 'dim' in the note.")
  }

  # Determine table suffix
  table_type <- tolower(stringr::str_extract(user_note, "\\b(fact|dim)\\b"))
  if (is.na(table_type)) {
    stop("❌ Your `user_note` must clearly include either 'fact' or 'dim'.")
  }

  # Clean dim_description for file name (if provided)
  if (!is.null(dim_description)) {
    dim_description <- janitor::make_clean_names(dim_description)
  }

  # Build enhanced table name
  final_table_name <- paste0(
    table_name,
    if (!is.null(dim_description)) paste0("_", dim_description),
    "_", table_type
  )

  # Auto-generate saving path, T drive specific
  if (is.null(path)) {
    warehouse_dir <- "T:/Data Warehouse/Warehouse Ready Files"
    path <- file.path(warehouse_dir,
                      as.character(data_year),
                      "Data Files",
                      folder_data_source,
                      paste0(final_table_name, ".csv"))

    # Make sure the folder exists
    dir.create(dirname(path), recursive = TRUE, showWarnings = FALSE)
  }

  # Apply compression if requested
  if (compress && !grepl("\\.gz$", path)) {
    path <- paste0(path, ".gz")
  }

  # Determine table type from user_note
  table_type <- tolower(stringr::str_extract(log_metadata$user_note, "\\b(fact|dim)\\b"))

  # Define allowed char columns based on table type
  allowed_char_cols <- if (table_type == "dim") {
    c("cds", "county_code", "district_code", "school_code")
  } else if (table_type == "fact") {
    c("cds")
  } else {
    stop("❌ Could not determine table type from `user_note`. Please include 'fact' or 'dim'.")
  }

  # Filter to only existing columns in the data
  existing_char_cols <- intersect(allowed_char_cols, names(data))

  # Coerce character columns
  data <- data %>%
    mutate(across(all_of(existing_char_cols), as.character))

  # Write the file
  fwrite(data, path)
  message("✅ File written: ", path)

  # Preview first n rows with character column types enforced
  print(fread(path, nrows = n_check,
              colClasses = list(character = existing_char_cols)))

  # File info
  file_info <- file.info(path)
  if (is.na(file_info$size)) {
    stop("File does not exist or is unreadable: ", path)
  }

  canonical_table_id <- if (is.null(canonical_table_id)) table_name else canonical_table_id
  dimension_type     <- if (is.null(dimension_type)) NA_character_ else dimension_type

  valid_dimension_types <- c("universal", "annualized", "other")
  if (!is.null(dimension_type) && !is.na(dimension_type)) {
    if (!tolower(dimension_type) %in% valid_dimension_types) {
      stop("❌ `dimension_type` must be one of: ",
           paste(valid_dimension_types, collapse = ", "))
    }
    dimension_type <- tolower(dimension_type)
  }

  # Construct and write log entry
  log_entry <- data.frame(
    timestamp = format(Sys.time(), "%Y-%m-%d %H:%M:%S"),
    file_name = paste0(final_table_name, if (compress) ".csv.gz" else ".csv"),
    file_path = normalizePath(path),
    file_size_MB = round(file_info$size / 1e6, 2),
    canonical_table_id = canonical_table_id,
    dimension_type = dimension_type,
    n_rows = nrow(data),
    n_cols = ncol(data),
    data_year = log_metadata$data_year,
    data_source = log_metadata$data_source,
    table_type = table_type,
    data_description = log_metadata$data_description,
    dim_description = dim_description %||% NA,
    user_note = log_metadata$user_note,
    user = Sys.info()[["user"]],
    stringsAsFactors = FALSE
  )

  # Read log if it exists
  if (file.exists(log_path)) {
    existing_log <- read.csv(log_path, stringsAsFactors = FALSE)

    # Overwrite row if file_path exists
    match_idx <- which(existing_log$canonical_table_id == canonical_table_id)

    if (length(match_idx) > 0) {
      existing_log[match_idx[1], ] <- log_entry
      write.csv(existing_log, file = log_path, row.names = FALSE)
      message("🔁 Existing log entry overwritten for: ", log_entry$file_name)
    } else {
      write.table(log_entry, file = log_path, append = TRUE, sep = ",",
                  row.names = FALSE, col.names = FALSE)
      message("📝 Log entry appended to: ", log_path)
    }
  } else {
    # New log file
    write.table(log_entry, file = log_path, append = FALSE, sep = ",",
                row.names = FALSE, col.names = TRUE)
    message("📄 New log created: ", log_path)
  }

  invisible(NULL)
}


##

sql_schema_log_warehouse <- function(data,
                           table_name,
                           data_year,
                           data_source,
                           user_note = NA,
                           dim_description = NULL,
                           max_char = 255,
                           primary_key = NULL,
                           foreign_keys = NULL,   # now supports named vector OR list-of-lists
                           canonical_table_id = NULL,
                           dimension_type = NULL) {

  # -----------------------------
  # Validate data_source
  # -----------------------------
  valid_sources <- c("Assessment", "CDE", "Dashboard")
  if (is.null(data_source) || !(tolower(data_source) %in% tolower(valid_sources))) {
    stop("❌ `data_source` must be one of: ", paste(valid_sources, collapse = ", "))
  }
  data_source_label <- valid_sources[match(tolower(data_source), tolower(valid_sources))]
  data_source_dir <- tolower(data_source_label)

  # -----------------------------
  # Validate user_note includes fact|dim and derive table_type
  # -----------------------------
  if (is.null(user_note) || !grepl("\\b(fact|dim)\\b", user_note, ignore.case = TRUE)) {
    stop("❌ Your `user_note` should clearly include either 'fact' or 'dim'.")
  }
  table_type <- tolower(stringr::str_extract(user_note, "\\b(fact|dim)\\b"))

  # -----------------------------
  # Clean dim_description (optional)
  # -----------------------------
  if (!is.null(dim_description)) {
    dim_description <- janitor::make_clean_names(dim_description)
  }

  # -----------------------------
  # Coerce to data.table and validate primary key
  # -----------------------------
  data <- data.table::as.data.table(data)

  if (is.null(primary_key)) {
    stop("❌ You should supply a primary key for this table using `primary_key`.")
  }
  if (!all(primary_key %in% names(data))) {
    stop("❌ The specified primary key does not exist in the dataset: ",
         paste(setdiff(primary_key, names(data)), collapse = ", "))
  }
  # Uniqueness checks
  if (length(primary_key) == 1 && anyDuplicated(data[[primary_key]]) > 0) {
    stop("❌ The primary key column '", primary_key, "' contains duplicates.")
  }
  if (length(primary_key) > 1 && anyDuplicated(data[, ..primary_key, drop = FALSE]) > 0) {
    stop("❌ The composite primary key (", paste(primary_key, collapse = ", "), ") contains duplicates.")
  }
  # Missing checks
  if (any(is.na(dplyr::select(data, dplyr::all_of(primary_key))))) {
    stop("❌ One or more of the primary key columns (",
         paste(primary_key, collapse = ", "), ") contain missing values.")
  }

  # -----------------------------
  # Foreign key normalization (backward-compatible)
  #   - Accepts named character vector: c(col = "ref_table")
  #   - Or list-of-lists: list(list(columns=c(...), ref_table="..."), ...)
  # -----------------------------
  normalize_foreign_keys <- function(fk, data_cols) {
    if (is.null(fk)) return(list())

    # Old style: named character vector
    if (is.character(fk) && !is.null(names(fk))) {
      fk <- purrr::imap(fk, ~ list(columns = .y, ref_table = .x, ref_column = .y))
    }

    if (!is.list(fk)) {
      stop("❌ `foreign_keys` should be a named character vector or a list of lists with `columns` and `ref_table` (and optionally `ref_column).")
    }

      # Validate each entry
    fk <- lapply(fk, function(x) {
      if (!all(c("columns", "ref_table") %in% names(x))) {
        stop("❌ Each foreign key should have `columns` and `ref_table` fields.")
      }

      cols <- as.character(x$columns)
      ref_cols <- if(!is.null(x$ref_column)) as.character(x$ref_column) else cols

      if(length(cols) != length(ref_cols)) {
        stop("❌ In foreign_keys: `columns` and `ref_column` must have the same length.")
      }

      if (!all(cols %in% data_cols)) {
        stop("❌ Foreign key columns not found in the dataset: ",
             paste(setdiff(cols, data_cols), collapse = ", "))
      }
      list(columns = cols,
           ref_table = as.character(x$ref_table)[1],
           ref_column = ref_cols)
    })

    fk
  }

  foreign_keys <- normalize_foreign_keys(foreign_keys, names(data))

  # -----------------------------
  # Dimension type validation (optional)
  # -----------------------------
  canonical_table_id <- canonical_table_id %||% table_name

  dimension_type <- dimension_type %||% NA

  valid_dimension_types <- c("universal", "annualized", "other")
  if (!is.null(dimension_type) && !is.na(dimension_type)) {
    if (!tolower(dimension_type) %in% valid_dimension_types) {
      stop("❌ `dimension_type` should be one of: ",
           paste(valid_dimension_types, collapse = ", "))
    }
    dimension_type <- tolower(dimension_type)
  }

  # -----------------------------
  # Helper: infer SQL type
  # -----------------------------
  measure_sql_type <- function(x) {
    if (is.character(x)) {
      max_len <- suppressWarnings(max(nchar(x[!is.na(x)]), na.rm = TRUE))
      if (!is.finite(max_len)) max_len <- max_char
      return(paste0("VARCHAR(", min(max_len, max_char), ")"))
    } else if (is.integer(x)) {
      return("INT")
    } else if (is.numeric(x)) {
      vals <- stats::na.omit(x)
      if (length(vals) == 0) return("DECIMAL(10, 2)")

      # pretty-format to count digits reliably (no scientific notation)
      f <- format(vals, scientific = FALSE, trim = TRUE)
      whole_digits <- nchar(gsub("\\..*$", "", f))               # digits left of decimal
      frac_digits  <- ifelse(grepl("\\.", f),
                             nchar(sub("^[^.]*\\.", "", f)), 0)  # digits right of decimal
      p <- suppressWarnings(max(whole_digits + frac_digits, na.rm = TRUE))
      s <- suppressWarnings(max(frac_digits, na.rm = TRUE))
      if (!is.finite(p)) p <- 10
      if (!is.finite(s)) s <- 4
      # If no fractional digits detected, use INT
      if (s == 0) return("INT")
      return(paste0("DECIMAL(", p, ", ", s, ")"))
    }
      else if (is.logical(x)) {
      return("BIT")
    } else {
      return("NVARCHAR(MAX)")
    }
  }

  current_cols <- names(data)

  # -----------------------------
  # Build enhanced final table name
  # -----------------------------
  final_table_name <- paste0(
    table_name,
    if (!is.null(dim_description)) paste0("_", dim_description),
    "_", table_type
  )

  # -----------------------------
  # Build FK column map for schema logging
  # -----------------------------
  fk_column_map <- if (length(foreign_keys) == 0) {
    tibble::tibble(column = character(), ref_column = character(), ref_table = character(), fk_group = character(), ref_group = character())
  } else {
    purrr::map_dfr(foreign_keys, function(fk) {
      tibble::tibble(
        column     = fk$columns,
        ref_column = fk$ref_column,
        ref_table  = fk$ref_table,
        fk_group   = paste(fk$columns, collapse = " + "),
        ref_group  = paste(fk$ref_column, collapse = " + ")
      )
    })
  }

  # -----------------------------
  # Build schema tibble
  # -----------------------------
  # Make fk_column_map unique just in case
  fk_column_map <- dplyr::distinct(fk_column_map)

  schema <- tibble::tibble(
    table_name      = final_table_name,
    column_name     = current_cols,
    sql_type        = purrr::map_chr(data, measure_sql_type),
    null_flag       = purrr::map_chr(data, ~ ifelse(any(is.na(.x)), "NULL", "NOT NULL")),
    is_primary_key  = ifelse(current_cols %in% primary_key, "YES", "NO"),
    is_foreign_key  = ifelse(current_cols %in% fk_column_map$column, "YES", "NO"),

    # ✅ collapse multiple refs for a column into one string
    foreign_key_ref = purrr::map_chr(current_cols, function(col) {
      rows <- dplyr::filter(fk_column_map, column == col)
      if (nrow(rows) > 0) {
        paste0(paste0(rows$ref_table, "(", rows$ref_column, ")"), collapse = " | ")
      } else NA_character_
    }),

    # ✅ likewise, collapse multiple groups if the column participates in multiple composites
    foreign_key_group = purrr::map_chr(current_cols, function(col) {
      rows <- dplyr::filter(fk_column_map, column == col)
      if (nrow(rows) > 0) paste(unique(rows$fk_group), collapse = " | ") else NA_character_
    }),

    primary_key_group = ifelse(
      current_cols %in% primary_key,
      paste(primary_key, collapse = " + "),
      NA_character_
    ),
    ref_key_group = purrr::map_chr(current_cols, function(col) {
      rows <- dplyr::filter(fk_column_map, column == col)
      if (nrow(rows) > 0) paste(unique(rows$ref_group), collapse = " | ") else NA_character_
    }),
    dimension_type     = dimension_type,
    data_year          = data_year,
    data_source        = data_source_label,
    dim_description    = dim_description %||% NA,
    canonical_table_id = canonical_table_id,
    user_note          = user_note %||% NA,
    timestamp          = format(Sys.time(), "%Y-%m-%d %H:%M:%S"),
    user               = Sys.info()[["user"]]
  ) %>%
    dplyr::select(
      table_name, column_name, sql_type, null_flag,
      is_primary_key, is_foreign_key, foreign_key_ref, foreign_key_group,
      primary_key_group, ref_key_group, dimension_type, data_year, data_source,
      canonical_table_id, dim_description, user_note, timestamp, user
    )

  # -----------------------------
  # Persist schema logs
  # -----------------------------
  base_dir <- "T:/Data Warehouse/Warehouse Ready Files"
  schema_log_dir <- file.path(base_dir, "schema_files")
  primary_log_path <- file.path(schema_log_dir, "primary_sql_schema_log.csv")

  if (!dir.exists(dirname(primary_log_path))) {
    dir.create(dirname(primary_log_path), recursive = TRUE)
  }

  if (file.exists(primary_log_path)) {
    existing_log <- readr::read_csv(primary_log_path, show_col_types = FALSE)

    existing_log$timestamp <- as.character(existing_log$timestamp)

    # Replace rows for this canonical_table_id (keeps latest single-table snapshot)
    schema <- dplyr::bind_rows(
      dplyr::filter(existing_log, canonical_table_id != !!canonical_table_id),
      schema
    )
  }

  # Always reset; changes flagged separately later
  schema$rebuild_flag <- 0

  readr::write_csv(schema, primary_log_path)
  message("🧾 Primary schema log updated at: ", primary_log_path)

  # Per-table schema file
  individual_path <- file.path(
    schema_log_dir,
    as.character(data_year),
    data_source_dir,
    table_type,
    paste0(final_table_name, "_schema.csv")
  )
  if (!dir.exists(dirname(individual_path))) {
    dir.create(dirname(individual_path), recursive = TRUE)
  }

  current_schema <- dplyr::filter(schema, table_name == !!final_table_name)
  readr::write_csv(current_schema, individual_path)
  message("📄 Table-level schema saved at: ", individual_path)

  invisible(schema)
}

###

# this is a wrapper function to combine safe_fwrite & sql_schema_log together!
export_with_schema_warehouse <- function(data,
                               path = NULL,
                               table_name,
                               data_year,
                               data_source,
                               data_description,
                               dim_description = NULL,
                               user_note,
                               char_cols = c("cds", "county_code", "district_code", "school_code"),
                               compress = FALSE,
                               n_check = 6,
                               export_log_path = "T:/Data Warehouse/Warehouse Ready Files/export_log.csv",
                               max_char = 255,
                               primary_key = NULL,
                               foreign_keys = NULL,
                               canonical_table_id = NULL,
                               dimension_type = NULL) {

  validate_sql_identifiers(table_name, type = "table")

  validate_sql_identifiers(names(data), type = "column")

  # Run safe_fwrite
  safe_fwrite_warehouse(
    data = data,
    path = path,
    char_cols = char_cols,
    compress = compress,
    n_check = n_check,
    data_year = data_year,
    data_source = data_source,
    data_description = data_description,
    dim_description = dim_description,
    user_note = user_note,
    table_name = table_name,
    log_path = export_log_path,
    canonical_table_id = canonical_table_id,
    dimension_type = dimension_type
  )

  # Run sql_schema_log
  sql_schema_log_warehouse(
    data = data,
    table_name = table_name,
    data_year = data_year,
    data_source = data_source,
    user_note = user_note,
    dim_description = dim_description,
    max_char = max_char,
    primary_key = primary_key,
    foreign_keys = foreign_keys,
    canonical_table_id = canonical_table_id,
    dimension_type = dimension_type
  )

  invisible(NULL)
}

## example usage
# validate_primary_key(chronic_entities_joined, c("cds", "year"))
# export_with_schema_warehouse(chronic_entities_joined, table_name = "chronic_entities_joined_dim",
#                              data_source = "cde", data_year = "2019_2024",
#                              data_description = "2019 & 2024 chronic absenteeism file entities dim",
#                              primary_key = c("cds", "year"),
#                              foreign_keys = list(
#                                list(columns = c("school_code", "year"), ref_table = "chronic_schools_joined_dim"),
#                                list(columns = c("district_code", "year"), ref_table = "chronic_districts_joined_dim"),
#                                list(columns = "county_code", ref_table = "chronic_counties_joined_dim")),
#                              dimension_type = "annualized", user_note = "dim table. There is also a chronic by reason file"
# )

# FUNCTION YOU NEED FOR THIS TO WORK ####
class_map_to_dim <- function(entry) {
  tibble::tibble(
    demo_group = entry$label,
    demo_group_num = entry$num,
    demo_group_group_num = entry$group_num,
    demo_group_group = entry$group
  )
}

# CDE CLASSIFICATION MAP AND DIM ####
cde_classification_map <- list(
  list(values = c("RB", "RE_B"), label = "African American", num = 1, group_num = 1, group = "Race"),
  list(values = c("RI", "RE_I"), label = "American Indian or Alaska Native", num = 2, group_num = 1, group = "Race"),
  list(values = c("RA", "RE_A"), label = "Asian", num = 3, group_num = 1, group = "Race"),
  list(values = c("RF", "RE_F"), label = "Filipino", num = 4, group_num = 1, group = "Race"),
  list(values = c("RH", "RE_H"), label = "Hispanic or Latino", num = 5, group_num = 1, group = "Race"),
  list(values = c("RP", "RE_P"), label = "Pacific Islander", num = 6, group_num = 1, group = "Race"),
  list(values = c("RT", "RE_T"), label = "Two or More Races", num = 7, group_num = 1, group = "Race"),
  list(values = c("RW", "RE_W"), label = "White", num = 8, group_num = 1, group = "Race"),
  list(values = c("RD", "RE_D"), label = "Race Not Reported", num = 9, group_num = 1, group = "Race"),
  list(values = c("GRKN", "GRK"), label = "Kindergarten", num = 10, group_num = 2, group = "Grade"),
  list(values = c("GR13"), label = "Grades 1-3", num = 11, group_num = 2, group = "Grade"),
  list(values = c("GS_46", "GR46"), label = "Grades 4-6", num = 12, group_num = 2, group = "Grade"),
  list(values = c("GR78"), label = "Grades 7-8", num = 13, group_num = 2, group = "Grade"),
  list(values = c("GRK8"), label = "Grades K-8", num = 14, group_num = 2, group = "Grade"),
  list(values = c("GS_912", "GR912"), label = "Grades 9-12", num = 15, group_num = 2, group = "Grade"),
  list(values = c("GRTKKN"), label = "Grades TK-K", num = 16, group_num = 2, group = "Grade"),
  list(values = c("GRTK8"), label = "Grades TK-8", num = 17, group_num = 2, group = "Grade"),
  list(values = c("GRTK"), label = "Grade TK", num = 18, group_num = 2, group = "Grade"),
  list(values = c("GR04"), label = "Grade 4", num = 19, group_num = 2, group = "Grade"),
  list(values = c("GR08"), label = "Grade 8", num = 20, group_num = 2, group = "Grade"),
  list(values = c("GR09"), label = "Grade 9", num = 21, group_num = 2, group = "Grade"),
  list(values = c("GR10"), label = "Grade 10", num = 22, group_num = 2, group = "Grade"),
  list(values = c("GR11"), label = "Grade 11", num = 23, group_num = 2, group = "Grade"),
  list(values = c("GR12"), label = "Grade 12", num = 24, group_num = 2, group = "Grade"),
  list(values = c("GS_PS3"), label = "Grades PreK-3", num = 25, group_num = 2, group = "Grade"),
  list(values = c("AR_03"), label = "Children K-12 who are 0-3", num = 26, group_num = 3, group = "Age Range"),
  list(values = c("AR_0418"), label = "Children K-12 who are 4-18", num = 27, group_num = 3, group = "Age Range"),
  list(values = c("AR_1922"), label = "Continuing Students K-12 who are 19-12", num = 28, group_num = 3, group = "Age Range"),
  list(values = c("AR_2329"), label = "Adults K-12 who are 23-29", num = 29, group_num = 3, group = "Age Range"),
  list(values = c("AR_3039"), label = "Adults K-12 who are 30-39", num = 30, group_num = 3, group = "Age Range"),
  list(values = c("AR_4049"), label = "Adults K-12 who are 40-49", num = 31, group_num = 3, group = "Age Range"),
  list(values = c("AR_50P"), label = "Adults K-12 who are 50 plus", num = 32, group_num = 3, group = "Age Range"),
  list(values = c("GN_F", "GF"), label = "Female", num = 33, group_num = 4, group = "Gender"),
  list(values = c("GN_M", "GM"), label = "Male", num = 34, group_num = 4, group = "Gender"),
  list(values = c("GN_X", "GX", "GN"), label = "Non-Binary", num = 35, group_num = 4, group = "Gender"),
  list(values = c("GN_Z", "GX", "GZ"), label = "Gender Missing", num = 36, group_num = 4, group = "Gender"),
  list(values = c("SG_EL", "SE", "ELAS_EL"), label = "English Learner", num = 37, group_num = 8, group = "English Language Acquisition Status"),
  list(values = c("SG_DS", "SD"), label = "Students with Disabilities", num = 38, group_num = 5, group = "Student Subgroup"),
  list(values = c("SG_SD", "SS"), label = "Socioeconomically Disadvantaged", num = 39, group_num = 5, group = "Student Subgroup"),
  list(values = c("SG_MG", "SM"), label = "Migrant Youth", num = 40, group_num = 5, group = "Student Subgroup"),
  list(values = c("SG_FS", "SF"), label = "Foster Youth", num = 41, group_num = 5, group = "Student Subgroup"),
  list(values = c("SG_HM", "SH"), label = "Homeless Youth", num = 42, group_num = 5, group = "Student Subgroup"),
  list(values = c("S5"), label = "Student with a 504 Accommodation Plan", num = 43, group_num = 5, group = "Student Subgroup"),
  list(values = c("HUYN"), label = "Not Homeless Unaccompanied Youth", num = 44, group_num = 5, group = "Student Subgroup"),
  list(values = c("HUYY"), label = "Homeless Unaccompanied Youth", num = 45, group_num = 5, group = "Student Subgroup"),
  list(values = c("EL_Y"), label = "Is an English Learner", num = 46, group_num = 8, group = "English Language Acquisition Status"),
  list(values = c("EL_Y"), label = "Is Not an English Learner", num = 47, group_num = 8, group = "English Language Acquisition Status"),
  list(values = c("CAY"), label = "Is Chronically Absent", num = 48, group_num = 5, group = "Student Subgroup"),
  list(values = c("CAN"), label = "Is Not Chronically Absent", num = 49, group_num = 5, group = "Student Subgroup"),
  list(values = c("TA"), label = "Total Number of Students", num = 50, group_num = 6, group = "Total Number of Students"),
  list(values = c("ELAS_ADEL"), label = "Adult English Learner", num = 51, group_num = 8, group = "English Language Acquisition Status"),
  list(values = c("ELAS_EO"), label = "English Only", num = 52, group_num = 8, group = "English Language Acquisition Status"),
  list(values = c("ELAS_IFEP"), label = "Initial Fluent English Proficient", num = 53, group_num = 8, group = "English Language Acquisition Status"),
  list(values = c("ELAS_MISS"), label = "EL Status Missing", num = 54, group_num = 8, group = "English Language Acquisition Status"),
  list(values = c("ELAS_RFEP"), label = "Reclassified Fluent English Proficient", num = 55, group_num = 8, group = "English Language Acquisition Status"),
  list(values = c("ELAS_TBD"), label = "English Status TBD", num = 56, group_num = 8, group = "English Language Acquisition Status"),
  list(values = c("DC_AUT"), label = "Autism", num = 57, group_num = 7, group = "Disability Category"),
  list(values = c("DC_DB"), label = "Deaf Blindedness", num = 58, group_num = 7, group = "Disability Category"),
  list(values = c("DC_DFHI"), label = "Deaf/Hearing Impairment", num = 59, group_num = 7, group = "Disability Category"),
  list(values = c("DC_ED"), label = "Emotional Disturbance", num = 60, group_num = 7, group = "Disability Category"),
  list(values = c("DC_EMD"), label = "Established Medical Disability", num = 61, group_num = 7, group = "Disability Category"),
  list(values = c("DC_HH"), label = "Hard of Hearing", num = 62, group_num = 7, group = "Disability Category"),
  list(values = c("DC_ID"), label = "Intellectual Disability", num = 63, group_num = 7, group = "Disability Category"),
  list(values = c("DC_MD"), label = "Multiple Disabilities", num = 64, group_num = 7, group = "Disability Category"),
  list(values = c("DC_OHI"), label = "Other Health Impairment", num = 65, group_num = 7, group = "Disability Category"),
  list(values = c("DC_OI"), label = "Orthopedic Health Impairment", num = 66, group_num = 7, group = "Disability Category"),
  list(values = c("DC_SLD"), label = "Specific Learning Disability", num = 67, group_num = 7, group = "Disability Category"),
  list(values = c("DC_SLI"), label = "Speech or Language Impairment", num = 68, group_num = 7, group = "Disability Category"),
  list(values = c("DC_TBI"), label = "Traumatic Brain Injury", num = 69, group_num = 7, group = "Disability Category"),
  list(values = c("DC_VI"), label = "Visual Impairment", num = 70, group_num = 7, group = "Disability Category"),
  list(values = c("AR_35"), label = "Ages 3-5", num = 71, group_num = 3, group = "Age Range"),
  list(values = c("AR_612"), label = "Ages 6-12", num = 72, group_num = 3, group = "Age Range"),
  list(values = c("AR_1318"), label = "Ages 13-18", num = 73, group_num = 3, group = "Age Range"),
  list(values = c("AR_19P"), label = "Ages 19 plus", num = 74, group_num = 3, group = "Age Range")
)

cde_demo_dim_table <- map_dfr(cde_classification_map, class_map_to_dim)

# DASHBOARD CLASSIFICATION MAP AND DIM ####
dashboard_classification_map <- list(
  list(values = c("AA"), label = "Black/African American", num = 1, group_num = 1, group = "Race"),
  list(values = c("AI"), label = "American Indian or Alaska Native", num = 2, group_num = 1, group = "Race"),
  list(values = c("AS"), label = "Asian", num = 3, group_num = 1, group = "Race"),
  list(values = c("FI"), label = "Filipino", num = 4, group_num = 1, group = "Race"),
  list(values = c("HI"), label = "Hispanic", num = 5, group_num = 1, group = "Race"),
  list(values = c("PI"), label = "Pacific Islander", num = 6, group_num = 1, group = "Race"),
  list(values = c("MR"), label = "Multiple Races/Two or More", num = 7, group_num = 1, group = "Race"),
  list(values = c("WH"), label = "White", num = 8, group_num = 1, group = "Race"),
  list(values = c("SED"), label = "Socioeconomically Disadvantaged", num = 9, group_num = 2, group = "Student Subgroup"),
  list(values = c("SWD"), label = "Students with Disabilities", num = 10, group_num = 2, group = "Student Subgroup"),
  list(values = c("FOS"), label = "Foster Youth", num = 11, group_num = 2, group = "Student Subgroup"),
  list(values = c("HOM"), label = "Homeless Youth", num = 12, group_num = 2, group = "Student Subgroup"),
  list(values = c("RFP"), label = "Recently Reclassified Fluent-English Proficient Only", num = 13, group_num = 4, group = "English Language Acquisition Status"),
  list(values = c("LTEL"), label = "Long-Term English Learner", num = 14, group_num = 2, group = "Student Subgroup"),
  list(values = c("SBA"), label = "Students Who Took SBAC", num = 15, group_num = 3, group = "Test Taken"),
  list(values = c("CAA"), label = "Students Who Took CAA", num = 16, group_num = 3, group = "Test Taken"),
  list(values = c("CAST"), label = "Students Who Took CAST", num = 17, group_num = 3, group = "Test Taken"),
  list(values = c("EL"), label = "English Learner", num = 18, group_num = 4, group = "English Language Acquisition Status"),
  list(values = c("ELO"), label = "English Learners Only", num = 19, group_num = 4, group = "English Language Acquisition Status"),
  list(values = c("EO"), label = "English Only", num = 20, group_num = 4, group = "English Language Acquisition Status")
)

dashboard_demo_dim_table <- map_dfr(dashboard_classification_map, class_map_to_dim)

#ASSESSMENT CLASSIFICATION MAP AND DIM
assessment_classification_map <- list(
  list(values = c(74), label = "Black or African American", num = 1, group_num = 1, group = "Race"),
  list(values = c(75), label = "American Indian or Alaska Native", num = 2, group_num = 1, group = "Race"),
  list(values = c(76), label = "Asian", num = 3, group_num = 1, group = "Race"),
  list(values = c(77), label = "Filipino", num = 4, group_num = 1, group = "Race"),
  list(values = c(78), label = "Hispanic or Latino", num = 5, group_num = 1, group = "Race"),
  list(values = c(79), label = "Native Hawaiian or Pacific Islander", num = 6, group_num = 1, group = "Race"),
  list(values = c(144), label = "Two or More Races", num = 7, group_num = 1, group = "Race"),
  list(values = c(80), label = "White", num = 8, group_num = 1, group = "Race"),
  list(values = c("KN"), label = "Kindergarten", num = 9, group_num = 2, group = "Grade"),
  list(values = c(1, "01"), label = "Grade 1", num = 10, group_num = 2, group = "Grade"),
  list(values = c(2, "02"), label = "Grade 2", num = 11, group_num = 2, group = "Grade"),
  list(values = c(3, "03"), label = "Grade 3", num = 12, group_num = 2, group = "Grade"),
  list(values = c(4, "04"), label = "Grade 4", num = 13, group_num = 2, group = "Grade"),
  list(values = c(5, "05"), label = "Grade 5", num = 14, group_num = 2, group = "Grade"),
  list(values = c(6, "06"), label = "Grade 6", num = 15, group_num = 2, group = "Grade"),
  list(values = c(7, "07"), label = "Grade 7", num = 16, group_num = 2, group = "Grade"),
  list(values = c(81, "08"), label = "Grade 8", num = 17, group_num = 2, group = "Grade"), #manual c() value to avoid forced duplicates
  list(values = c(9, "09"), label = "Grade 9", num = 18, group_num = 2, group = "Grade"),
  list(values = c(10, "10"), label = "Grade 10", num = 19, group_num = 2, group = "Grade"),
  list(values = c(11, "11"), label = "Grade 11", num = 20, group_num = 2, group = "Grade"),
  list(values = c(12, "12"), label = "Grade 12", num = 21, group_num = 2, group = "Grade"),
  list(values = c(13, "13"), label = "All Grades", num = 22, group_num = 2, group = "Grade"),
  list(values = c(14), label = "All High School Grades", num = 23, group_num = 2, group = "Grade"),
  list(values = c(991), label = "Cohort Grade/Graduating Class", num = 24, group_num = 2, group = "Grade"), #manual c() value to avoid forced duplicates
  list(values = c(4), label = "Female", num = 25, group_num = 3, group = "Gender"),
  list(values = c(3), label = "Male", num = 26, group_num = 3, group = "Gender"),
  list(values = c(28), label = "Migrant Youth", num = 27, group_num = 4, group = "Student Subgroup"),
  list(values = c(29), label = "Not Migrant Youth", num = 28, group_num = 4, group = "Student Subgroup"),
  list(values = c(52), label = "Homeless Youth", num = 29, group_num = 4, group = "Student Subgroup"),
  list(values = c(53), label = "Not Homeless Youth", num = 30, group_num = 4, group = "Student Subgroup"),
  list(values = c(240), label = "Foster Youth", num = 31, group_num = 4, group = "Student Subgroup"),
  list(values = c(241), label = "Not Foster Youth", num = 32, group_num = 4, group = "Student Subgroup"),
  list(values = c(50), label = "Armed Forces Family Member", num = 33, group_num = 4, group = "Student Subgroup"),
  list(values = c(51), label = "No Armed Forces Family Member", num = 34, group_num = 4, group = "Student Subgroup"),
  list(values = c(1), label = "All Students", num = 35, group_num = 4, group = "Student Subgroup"),
  list(values = c(128), label = "Student with a Disability", num = 36, group_num = 4, group = "Student Subgroup"),
  list(values = c(99), label = "Student Without a Disability", num = 37, group_num = 4, group = "Student Subgroup"),
  list(values = c(239), label = "Student with a Disability Tested with Alternate Assessment", num = 38, group_num = 5, group = "Test Taken"),
  list(values = c(31), label = "Socioeconomically Disadvantaged", num = 39, group_num = 4, group = "Student Subgroup"),
  list(values = c(111), label = "Not Socioeconomically Disadvantaged", num = 40, group_num = 4, group = "Student Subgroup"),
  list(values = c(6), label = "IFEP, RFEP and EO", num = 41, group_num = 6, group = "English Language Acquisition Status"),
  list(values = c(7), label = "IFEP", num = 42, group_num = 6, group = "English Language Acquisition Status"),
  list(values = c(8), label = "RFEP", num = 43, group_num = 6, group = "English Language Acquisition Status"),
  list(values = c(120), label = "ELs Enrolled Less Than 12 Months", num = 44, group_num = 6, group = "English Language Acquisition Status"),
  list(values = c(142), label = "ELs Enrolled 12 Months or More", num = 45, group_num = 6, group = "English Language Acquisition Status"),
  list(values = c(160), label = "English Learner", num = 46, group_num = 6, group = "English Language Acquisition Status"),
  list(values = c(243), label = "Adult English Learner Only", num = 47, group_num = 6, group = "English Language Acquisition Status"),
  list(values = c(180), label = "English Only", num = 48, group_num = 6, group = "English Language Acquisition Status"),
  list(values = c(170), label = "Ever-EL", num = 49, group_num = 6, group = "English Language Acquisition Status"),
  list(values = c(250), label = "Long-Term English Learner", num = 50, group_num = 6, group = "English Language Acquisition Status"),
  list(values = c(251), label = "At-Risk of Becoming LTEL", num = 51, group_num = 6, group = "English Language Acquisition Status"),
  list(values = c(252), label = "Never an English Learner", num = 52, group_num = 6, group = "English Language Acquisition Status"),
  list(values = c(190), label = "English Language Acquisition Status TBD", num = 53, group_num = 6, group = "English Language Acquisition Status"),
  list(values = c(242), label = "English Learner - 1 Year in Program", num = 54, group_num = 6, group = "English Language Acquisition Status"),
  list(values = c(243), label = "English Learner - 2 Years in Program", num = 55, group_num = 6, group = "English Language Acquisition Status"),
  list(values = c(244), label = "English Learner - 3 Years in Program", num = 56, group_num = 6, group = "English Language Acquisition Status"),
  list(values = c(245), label = "English Learner - 4 Years in Program", num = 57, group_num = 6, group = "English Language Acquisition Status"),
  list(values = c(246), label = "English Learner - 5 Years in Program", num = 58, group_num = 6, group = "English Language Acquisition Status"),
  list(values = c(247), label = "English Learner - 6 Years in Program", num = 59, group_num = 6, group = "English Language Acquisition Status"),
  list(values = c(228), label = "Spanish", num = 60, group_num = 7, group = "First Language"),
  list(values = c(229), label = "Vietnamese", num = 61, group_num = 7, group = "First Language"),
  list(values = c(230), label = "Mandarin (Putonghua)", num = 62, group_num = 7, group = "First Language"),
  list(values = c(231), label = "Arabic", num = 63, group_num = 7, group = "First Language"),
  list(values = c(232), label = "Filipino (Pilipino or Tagalog)", num = 64, group_num = 7, group = "First Language"),
  list(values = c(233), label = "Cantonese", num = 65, group_num = 7, group = "First Language"),
  list(values = c(234), label = "Korean", num = 66, group_num = 7, group = "First Language"),
  list(values = c(235), label = "Hmong", num = 67,group_num = 7,  group = "First Language"),
  list(values = c(236), label = "Punjabi", num = 68, group_num = 7, group = "First Language"),
  list(values = c(237), label = "Russian", num = 69, group_num = 7, group = "First Language"),
  list(values = c(238), label = "All Remaining Languages", num = 70, group_num = 7, group = "First Language"),
  list(values = c(90), label = "Not a High School Graduate", num = 71, group_num = 8, group = "Parent Education"),
  list(values = c(91), label = "High School Graduate", num = 72, group_num = 8, group = "Parent Education"),
  list(values = c(92), label = "Some College (Includes AA Degree)", num = 73, group_num = 8, group = "Parent Education"),
  list(values = c(93), label = "College Graduate", num = 74, group_num = 8, group = "Parent Education"),
  list(values = c(94), label = "Graduate School/Post Graduate", num = 75, group_num = 8, group = "Parent Education"),
  list(values = c(121), label = "Declined to State", num = 76, group_num = 8, group = "Parent Education"),
  list(values = c(201), label = "American Indian or Alaska Native and Economically Disadvantaged", num = 77, group_num = 9, group = "Crosstabs"),
  list(values = c(202), label = "Asian and Economically Disadvantaged", num = 78, group_num = 9, group = "Crosstabs"),
  list(values = c(200), label = "Black or African American and Economically Disadvantaged", num = 79, group_num = 9, group = "Crosstabs"),
  list(values = c(203), label = "Filipino and Economically Disadvantaged", num = 80, group_num = 9, group = "Crosstabs"),
  list(values = c(204), label = "Hispanic or Latino and Economically Disadvantaged", num = 81, group_num = 9, group = "Crosstabs"),
  list(values = c(205), label = "Native Hawaiian or Pacific Islander and Economically Disadvantaged", num = 82, group_num = 9, group = "Crosstabs"),
  list(values = c(206), label = "White and Economically Disadvantaged", num = 83, group_num = 9, group = "Crosstabs"),
  list(values = c(207), label = "Two or More Races and Economically Disadvantaged", num = 84, group_num = 9, group = "Crosstabs"),
  list(values = c(221), label = "American Indian or Alaska Native and Not Economically Disadvantaged", num = 85, group_num = 9, group = "Crosstabs"),
  list(values = c(222), label = "Asian and Not Economically Disadvantaged", num = 86, group_num = 9, group = "Crosstabs"),
  list(values = c(220), label = "Black or African American and Not Economically Disadvantaged", num = 87, group_num = 9, group = "Crosstabs"),
  list(values = c(223), label = "Filipino and Not Economically Disadvantaged", num = 88, group_num = 9, group = "Crosstabs"),
  list(values = c(224), label = "Hispanic or Latino and Not Economically Disadvantaged", num = 89, group_num = 9, group = "Crosstabs"),
  list(values = c(225), label = "Native Hawaiian or Pacific Islander and Not Economically Disadvantaged", num = 90, group_num = 9, group = "Crosstabs"),
  list(values = c(226), label = "White and Not Economically Disadvantaged", num = 91, group_num = 9, group = "Crosstabs"),
  list(values = c(227), label = "Two or More Races and Not Economically Disadvantaged", num = 92, group_num = 9, group = "Crosstabs")
)

assessment_demo_dim_table <- map_dfr(assessment_classification_map, class_map_to_dim)


# Run audit for already CSVs with potential code padding issues ####

audit_codes_in_file <- function(
    path,
    fix       = FALSE,
    only_cols = c("cds","county_code","district_code","school_code"),
    cds_mode  = c("short","never","always"),
    widths    = c(cds = 14, county_code = 2, district_code = 5, school_code = 7),
    encoding  = "UTF-8"
) {
  cds_mode <- match.arg(cds_mode)
  stopifnot(file.exists(path))

  loc  <- readr::locale(encoding = encoding)
  hdr  <- readr::read_csv(path, n_max = 0, show_col_types = FALSE, locale = loc)
  cols_present <- intersect(names(widths), names(hdr))
  if (!length(cols_present)) {
    return(tibble::tibble(file = path, col = character(), n = integer(),
                          n_not_digit = integer(), n_wrong_len = integer(),
                          min_len = integer(), max_len = integer(), changed = integer()))
  }

  # read with code cols forced to character
  spec <- readr::cols(.default = readr::col_guess())
  for (nm in cols_present) spec$cols[[nm]] <- readr::col_character()
  df <- readr::read_csv(path, show_col_types = FALSE, locale = loc, col_types = spec)

  rep <- purrr::map_dfr(cols_present, function(nm) {
    v   <- df[[nm]]
    v0  <- v
    nch <- nchar(v, allowNA = TRUE)

    n             <- length(v)
    n_not_digit   <- sum(!grepl("^\\d*$", v %>% as.character()), na.rm = TRUE)
    n_short       <- sum(!is.na(nch) & nch < widths[[nm]])
    n_long        <- sum(!is.na(nch) & nch > widths[[nm]])
    n_wrong_len   <- n_short + n_long
    changed       <- 0L

    if (fix && nm %in% only_cols) {
      if (nm == "cds") {
        if (cds_mode == "short") {
          idx <- !is.na(v) & nchar(v) < widths[[nm]]
          v[idx] <- stringr::str_pad(v[idx], widths[[nm]], side = "left", pad = "0")
        } else if (cds_mode == "always") {
          v <- stringr::str_pad(v, widths[[nm]], side = "left", pad = "0")
        } # "never" -> do nothing
      } else {
        v <- stringr::str_pad(v, widths[[nm]], side = "left", pad = "0")
      }
      changed <- sum(v != v0, na.rm = TRUE)
      df[[nm]] <- v
    }

    tibble::tibble(file = path, col = nm, n = n,
                   n_not_digit = n_not_digit, n_wrong_len = n_wrong_len,
                   min_len = suppressWarnings(min(nch, na.rm = TRUE)),
                   max_len = suppressWarnings(max(nch, na.rm = TRUE)),
                   changed = changed)
  })

  if (fix && any(rep$changed > 0L)) {
    data.table::fwrite(df, path)
  }
  rep
}


audit_folder <- function(base_dir,
                         pattern = "\\.csv(\\.gz)?$",
                         fix = FALSE,
                         encoding = "UTF-8") {
  files <- list.files(base_dir, pattern = pattern, recursive = TRUE, full.names = TRUE)
  res <- purrr::map_dfr(files, ~audit_codes_in_file(.x, fix = fix, encoding = encoding))
  res
}

